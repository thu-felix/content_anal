dataset:
  name: tweet_topic
  path: cardiffnlp/super_tweeteval

environment:
  num_gpus: 1

reproduce:
    seed: 42

plm:
  model_name: t5
  model_path: t5-small
  optimize: 
    freeze_para: True

train:
  num_epochs: 5
  batch_size: 4
  teacher_forcing: True
  gradient_accumulation_steps: 2 
  gradient_clipping: 1.0 

task: generation

generation: # Adding any arguments for generation here.
  parent_config: task
  max_length: 512
  min_length: 3    
  temperature: 0.7  
  top_k: 50        
  top_p: 0.9       
  repetition_penalty: 2.0  
  num_beams: 5     
  metric: 
    - sentence_bleu  

learning_setting: few_shot # selecting from "full", "zero_shot", "few_shot"
few_shot:
  parent_config: learning_setting
  few_shot_sampling: sampling_from_train
  
sampling_from_train:
  parent_config: few_shot_sampling
  num_examples_per_label: 100
  also_sample_dev: True
  num_examples_per_label_dev: 100
  seed:
    - 123

template: soft_template
verbalizer: 

soft_template :
  choice: 0
  file_path: ./template.txt
