dataset:
  name: tweet_topic
  path: cardiffnlp/super_tweeteval

environment:
  num_gpus: 1

reproduce:
    seed: 42

plm:
  model_name: t5
  model_path: t5-small
  optimize: 
    freeze_para: True

train:
  num_epochs: 5
  batch_size: 2
  teacher_forcing: True
  gradient_accumulation_steps: 2 
  gradient_clipping: 1.0 

task: classification

classification:
  parent_config: task
  metric:  # the first one will be the main  to determine checkpoint.
    - accuracy  # whether the higher metric value is better.
    - micro-f1
    - macro-f1
    - precision
    - recall
  loss_function: bce_with_logits ## the loss function for classification

learning_setting: full # selecting from "full", "zero_shot", "few_shot"
few_shot:
  parent_config: learning_setting
  few_shot_sampling: sampling_from_train
  
sampling_from_train:
  parent_config: few_shot_sampling
  num_examples_per_label: 100
  also_sample_dev: True
  num_examples_per_label_dev: 100
  seed:
    - 123

template: soft_template
verbalizer: manual_verbalizer  

soft_template :
  choice: 0
  file_path: ./template.txt

manual_verbalizer:
  choice: 0
  file_path: ./verbalizer.txt

id2label:
  0: "arts_&_culture"
  1: "business_&_entrepreneurs"
  2: "celebrity_&_pop_culture"
  3: "diaries_&_daily_life"
  4: "family"
  5: "fashion_&_style"
  6: "film_tv_&_video"
  7: "fitness_&_health"
  8: "food_&_dining"
  9: "gaming"
  10: "learning_&_educational"
  11: "music"
  12: "news_&_social_concern"
  13: "other_hobbies"
  14: "relationships"
  15: "science_&_technology"
  16: "sports"
  17: "travel_&_adventure"
  18: "youth_&_student_life"
