environment:
  num_gpus: 1
#   cuda_visible_devices:
#     - 0
#   local_rank: 0
#

dataset:
  name: fakenews
  path: ./dataset

plm:
  model_name: t5
  model_path: t5-small
  optimize:
    freeze_para: True
    lr: 0.0005
    weight_decay: 0.01
    scheduler:
      type:
      num_warmup_steps: 500

dataloader:
  max_seq_length: 128

train:
  num_epochs: 10
  batch_size: 8
  gradient_accumulation_steps: 1

test:
  batch_size: 8

valid:
  batch_size: 8


template: mixed_template
verbalizer: manual_verbalizer


mixed_template:
  choice: 0
  file_path: ./soft_template.txt
#   optimize:
#     lr: 0.003
#     weight_decay: 0.0
#     scheduler:
#       num_warmup_steps: 0

manual_verbalizer:
  choice: 0
  file_path: ./verbalizer.txt
  
learning_setting: full


task: classification
classification:
  parent_config: task
  metric:  # the first one will be the main  to determine checkpoint.
    - accuracy  # whether the higher metric value is better.
    - micro-f1
    - macro-f1
    - precision
    - recall
  loss_function: cross_entropy ## the loss function for classification
